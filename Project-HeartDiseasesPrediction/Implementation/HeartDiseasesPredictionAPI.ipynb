{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "\n",
    "#library for saving the trained models to files\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Libraries for feature encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#feature encoding library\n",
    "from featureencodinglibrary import featureEncodingUsingOneHotEncoder\n",
    "\n",
    "#feature scaling library\n",
    "from featurescalinglibrary import featureScalingUsingNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predictHeartDiseaseUsingML', methods=['POST'])\n",
    "def predictHeartDiseaseUsingML():  \n",
    "    # use parser and find the user's query\n",
    "    jsonRequest = request.get_json()\n",
    "    \n",
    "    data = [jsonRequest]\n",
    "    testDataFrame = pd.DataFrame(data)\n",
    "    \n",
    "    #Perform the same preprocessing as performed on training dataset\n",
    "    testDataFrameEncoded = featureEncodingUsingOneHotEncoder(testDataFrame)\n",
    "    testDataFrameEncodedAndScaledDataset = featureScalingUsingNormalizer(testDataFrameEncoded)\n",
    "\n",
    "    #Load classifier from file\n",
    "    xtest = testDataFrameEncodedAndScaledDataset.iloc[:, :-1].values\n",
    "    ytest = testDataFrameEncodedAndScaledDataset.iloc[:, len(testDataFrameEncodedAndScaledDataset.columns)-1].values\n",
    "\n",
    "    labelencoder_ytest = LabelEncoder()\n",
    "    ytest = labelencoder_ytest.fit_transform(ytest)\n",
    "    # Predicting the Test set results\n",
    "    ytestpred = classifier.predict(xtest)\n",
    "    prediction = {'prediction':int(ytestpred[0])}\n",
    "    return jsonify(prediction)\n",
    "    #return '''ytestpred: {}'''.format(ytestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8080/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [06/Jan/2020 04:38:34] \"\u001b[37mPOST /predictHeartDiseaseUsingML HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Start one hot encoding on the categorical features in the given dataset *****\n",
      "****** Number of features before one hot encoding:  14\n",
      "****** Number of categorical features in the dataset:  0\n",
      "****** Categorical feature names in the dataset:  []\n",
      "\n",
      "****** Here is the list of unique values present in each categorical feature in the dataset *****\n",
      "\n",
      "****** Number of features after one hot encoding:  14\n",
      "****** End one hot encoding on the categorical features in the given dataset *****\n",
      "\n",
      "****** Start feature scaling of the features present in the dataset using Normalizer *****\n",
      "\n",
      "****** Number of features in the dataset before performing scaling:  13\n",
      "\n",
      "****** Features in the dataset before performing scaling ***** \n",
      " [[ 49.    1.    1.  130.  266.    0.    1.  171.    0.    0.6   2.    0.\n",
      "    2. ]]\n",
      "\n",
      "****** Number of features in the dataset after performing scaling:  13\n",
      "\n",
      "****** Features in the dataset after performing scaling ***** \n",
      " [[0.14185963 0.00289509 0.00289509 0.37636228 0.77009513 0.\n",
      "  0.00289509 0.49506116 0.         0.00173706 0.00579019 0.\n",
      "  0.00579019]]\n",
      "\n",
      "****** End of feature scaling of the features present in the dataset using Normalizer *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Jan/2020 04:38:41] \"\u001b[37mPOST /predictHeartDiseaseUsingML HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Start one hot encoding on the categorical features in the given dataset *****\n",
      "****** Number of features before one hot encoding:  14\n",
      "****** Number of categorical features in the dataset:  0\n",
      "****** Categorical feature names in the dataset:  []\n",
      "\n",
      "****** Here is the list of unique values present in each categorical feature in the dataset *****\n",
      "\n",
      "****** Number of features after one hot encoding:  14\n",
      "****** End one hot encoding on the categorical features in the given dataset *****\n",
      "\n",
      "****** Start feature scaling of the features present in the dataset using Normalizer *****\n",
      "\n",
      "****** Number of features in the dataset before performing scaling:  13\n",
      "\n",
      "****** Features in the dataset before performing scaling ***** \n",
      " [[ 49.    1.    1.  130.  266.    0.    1.  171.    0.    0.6   2.    0.\n",
      "    2. ]]\n",
      "\n",
      "****** Number of features in the dataset after performing scaling:  13\n",
      "\n",
      "****** Features in the dataset after performing scaling ***** \n",
      " [[0.14185963 0.00289509 0.00289509 0.37636228 0.77009513 0.\n",
      "  0.00289509 0.49506116 0.         0.00173706 0.00579019 0.\n",
      "  0.00579019]]\n",
      "\n",
      "****** End of feature scaling of the features present in the dataset using Normalizer *****\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "     classifier = joblib.load('OneHotEncoder_Normalizing_RandomForestClassifier.pkl')\n",
    "     app.run(port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
